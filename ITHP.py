import torch
import torch.nn as nn
import torch.nn.functional as F
import global_configs
import math


class CrossModalAttention(nn.Module):
    """è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶"""

    def __init__(self, query_dim, key_dim, value_dim, hidden_dim=256, num_heads=8):
        super(CrossModalAttention, self).__init__()
        self.num_heads = num_heads
        self.hidden_dim = hidden_dim
        self.head_dim = hidden_dim // num_heads

        assert hidden_dim % num_heads == 0, "hidden_dim must be divisible by num_heads"

        # æŠ•å½±å±‚
        self.query_proj = nn.Linear(query_dim, hidden_dim)
        self.key_proj = nn.Linear(key_dim, hidden_dim)
        self.value_proj = nn.Linear(value_dim, hidden_dim)
        self.output_proj = nn.Linear(hidden_dim, query_dim)

        # å±‚å½’ä¸€åŒ–å’Œdropout
        self.layer_norm = nn.LayerNorm(query_dim)
        self.dropout = nn.Dropout(0.1)

        self.scale = math.sqrt(self.head_dim)

    def forward(self, query, key, value, mask=None):
        batch_size, seq_len = query.shape[:2]

        # çº¿æ€§æŠ•å½±
        Q = self.query_proj(query)  # [batch_size, seq_len, hidden_dim]
        K = self.key_proj(key)  # [batch_size, seq_len, hidden_dim]
        V = self.value_proj(value)  # [batch_size, seq_len, hidden_dim]

        # é‡å¡‘ä¸ºå¤šå¤´æ ¼å¼
        Q = Q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        K = K.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        V = V.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)

        # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale

        if mask is not None:
            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)

        attention_weights = F.softmax(attention_scores, dim=-1)
        attention_weights = self.dropout(attention_weights)

        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
        attended_values = torch.matmul(attention_weights, V)

        # é‡å¡‘å›åŸå§‹ç»´åº¦
        attended_values = attended_values.transpose(1, 2).contiguous().view(
            batch_size, seq_len, self.hidden_dim
        )

        # è¾“å‡ºæŠ•å½±
        output = self.output_proj(attended_values)

        # æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–
        output = self.layer_norm(output + query)

        return output, attention_weights.mean(dim=1)  # è¿”å›å¹³å‡æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–


class LearnableWeights(nn.Module):
    """å¯å­¦ä¹ çš„æŸå¤±æƒé‡å‚æ•°"""

    def __init__(self, initial_beta=8.0, initial_gamma=32.0, initial_lambda=0.3):
        super(LearnableWeights, self).__init__()

        # ä½¿ç”¨logå‚æ•°ç¡®ä¿æƒé‡å§‹ç»ˆä¸ºæ­£
        self.log_beta = nn.Parameter(torch.log(torch.tensor(initial_beta, dtype=torch.float32)))
        self.log_gamma = nn.Parameter(torch.log(torch.tensor(initial_gamma, dtype=torch.float32)))
        self.log_lambda = nn.Parameter(torch.log(torch.tensor(initial_lambda, dtype=torch.float32)))

        # æ¸©åº¦å‚æ•°ç”¨äºæ§åˆ¶å­¦ä¹ é€Ÿåº¦
        self.temperature = nn.Parameter(torch.tensor(1.0))

    @property
    def beta(self):
        return torch.exp(self.log_beta / self.temperature)

    @property
    def gamma(self):
        return torch.exp(self.log_gamma / self.temperature)

    @property
    def lambda_weight(self):
        return torch.exp(self.log_lambda / self.temperature)

    def get_weights(self):
        """è¿”å›å½“å‰æƒé‡å€¼,ç”¨äºç›‘æ§"""
        return {
            'beta': self.beta.item(),
            'gamma': self.gamma.item(),
            'lambda': self.lambda_weight.item(),
            'temperature': self.temperature.item()
        }


class GatedBottleneck(nn.Module):
    """é—¨æ§ç“¶é¢ˆæœºåˆ¶"""

    def __init__(self, input_dim, bottleneck_dim, gate_activation='sigmoid'):
        super(GatedBottleneck, self).__init__()

        # é—¨æ§ç½‘ç»œ
        self.gate_network = nn.Sequential(
            nn.Linear(input_dim, bottleneck_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(bottleneck_dim, bottleneck_dim),
            nn.Sigmoid() if gate_activation == 'sigmoid' else nn.Tanh()
        )

        # ç¼–ç å™¨ç½‘ç»œ
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, bottleneck_dim * 2),  # è¾“å‡ºmuå’Œlogvar
        )

        # é‡è¦æ€§é—¨æ§(ç”¨äºç‰¹å¾é€‰æ‹©)
        self.importance_gate = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.Sigmoid()
        )

        # å±‚å½’ä¸€åŒ–
        self.layer_norm = nn.LayerNorm(input_dim)

    def forward(self, x):
        # è¾“å…¥ç‰¹å¾é‡è¦æ€§é—¨æ§
        importance_weights = self.importance_gate(x)
        gated_input = x * importance_weights
        gated_input = self.layer_norm(gated_input + x)  # æ®‹å·®è¿æ¥

        # è®¡ç®—é—¨æ§å€¼
        gate_values = self.gate_network(gated_input)

        # ç¼–ç 
        h = self.encoder(gated_input)
        mu, logvar = h.chunk(2, dim=-1)

        # åº”ç”¨é—¨æ§åˆ°å‡å€¼
        gated_mu = mu * gate_values

        # é—¨æ§ä¹Ÿå½±å“æ–¹å·®,ä½†ç¨‹åº¦è¾ƒå°
        gate_logvar_effect = torch.log(gate_values + 1e-8) * 0.1
        gated_logvar = logvar + gate_logvar_effect

        return gated_mu, gated_logvar, gate_values, importance_weights


class StandardBottleneck(nn.Module):
    """æ ‡å‡†ç“¶é¢ˆæœºåˆ¶(æ— é—¨æ§) - ç”¨äºæ¶ˆèå®éªŒ"""

    def __init__(self, input_dim, bottleneck_dim):
        super(StandardBottleneck, self).__init__()

        # ç¼–ç å™¨ç½‘ç»œ
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, bottleneck_dim * 2),  # è¾“å‡ºmuå’Œlogvar
        )

        # å±‚å½’ä¸€åŒ–
        self.layer_norm = nn.LayerNorm(input_dim)

    def forward(self, x):
        # å±‚å½’ä¸€åŒ–
        normalized_input = self.layer_norm(x)

        # ç¼–ç 
        h = self.encoder(normalized_input)
        mu, logvar = h.chunk(2, dim=-1)

        # è¿”å›æ ¼å¼ä¸GatedBottleneckä¿æŒä¸€è‡´ï¼Œä½†gate_valueså’Œimportance_weightsä¸ºNone
        return mu, logvar, None, None


class ITHP(nn.Module):
    """æ”¹è¿›çš„ITHPæ¨¡å‹"""

    def __init__(self, ITHP_args):
        super(ITHP, self).__init__()

        # åŸå§‹å‚æ•°
        TEXT_DIM, ACOUSTIC_DIM, VISUAL_DIM = (global_configs.TEXT_DIM, global_configs.ACOUSTIC_DIM,
                                              global_configs.VISUAL_DIM)

        self.X0_dim = ITHP_args['X0_dim']
        self.X1_dim = ITHP_args['X1_dim']
        self.X2_dim = ITHP_args['X2_dim']
        self.inter_dim = ITHP_args['inter_dim']
        self.drop_prob = ITHP_args['drop_prob']
        self.max_sen_len = ITHP_args['max_sen_len']
        self.B0_dim = ITHP_args['B0_dim']
        self.B1_dim = ITHP_args['B1_dim']

        # ğŸ”¥ é—¨æ§æ¨¡å¼é…ç½® - æ¶ˆèå®éªŒ
        self.gating_mode = ITHP_args.get('gating_mode', 'dual_gating')
        # å¯é€‰å€¼: 'no_gating', 'single_gating', 'dual_gating'

        # å¯å­¦ä¹ æƒé‡
        self.learnable_weights = LearnableWeights(
            initial_beta=ITHP_args.get('p_beta', 8.0),
            initial_gamma=ITHP_args.get('p_gamma', 32.0),
            initial_lambda=ITHP_args.get('p_lambda', 0.3)
        )

        # ================== ç¬¬ä¸€å±‚ç¼–ç å™¨ ==================
        if self.gating_mode == 'no_gating':
            # ä½¿ç”¨æ ‡å‡†ç“¶é¢ˆ(æ— é—¨æ§)
            self.gated_encoder1 = StandardBottleneck(self.X0_dim, self.B0_dim)
        else:
            # ä½¿ç”¨é—¨æ§ç“¶é¢ˆ (single_gating å’Œ dual_gating)
            self.gated_encoder1 = GatedBottleneck(self.X0_dim, self.B0_dim, gate_activation='sigmoid')

        # è·¨æ¨¡æ€æ³¨æ„åŠ›(æ–‡æœ¬-å£°å­¦)
        self.text_acoustic_attention = CrossModalAttention(
            query_dim=self.B0_dim,
            key_dim=self.X1_dim,
            value_dim=self.X1_dim,
            hidden_dim=min(256, self.B0_dim),
            num_heads=8
        )

        # ç¬¬ä¸€å±‚MLP(é‡æ„å£°å­¦ç‰¹å¾)
        self.MLP1 = nn.Sequential(
            nn.Linear(self.B0_dim, self.inter_dim),
            nn.ReLU(),
            nn.Dropout(self.drop_prob),
            nn.Linear(self.inter_dim, self.X1_dim),
            nn.Sigmoid(),
            nn.Dropout(self.drop_prob),
        )

        # ================== ç¬¬äºŒå±‚ç¼–ç å™¨ ==================
        if self.gating_mode == 'no_gating' or self.gating_mode == 'single_gating':
            # ä½¿ç”¨æ ‡å‡†ç“¶é¢ˆ(æ— é—¨æ§)
            self.gated_encoder2 = StandardBottleneck(self.B0_dim, self.B1_dim)
        else:
            # ä½¿ç”¨é—¨æ§ç“¶é¢ˆ (dual_gating)
            self.gated_encoder2 = GatedBottleneck(self.B0_dim, self.B1_dim, gate_activation='sigmoid')

        # è·¨æ¨¡æ€æ³¨æ„åŠ›(B0-è§†è§‰)
        self.b0_visual_attention = CrossModalAttention(
            query_dim=self.B1_dim,
            key_dim=self.X2_dim,
            value_dim=self.X2_dim,
            hidden_dim=min(256, self.B1_dim),
            num_heads=8
        )

        # ç¬¬äºŒå±‚MLP(é‡æ„è§†è§‰ç‰¹å¾)
        self.MLP2 = nn.Sequential(
            nn.Linear(self.B1_dim, self.inter_dim),
            nn.ReLU(),
            nn.Dropout(self.drop_prob),
            nn.Linear(self.inter_dim, self.X2_dim),
            nn.Sigmoid(),
            nn.Dropout(self.drop_prob),
        )

        # é¢å¤–çš„èåˆå±‚
        self.multimodal_fusion = nn.Sequential(
            nn.Linear(self.B1_dim + self.X1_dim + self.X2_dim, self.B1_dim),
            nn.ReLU(),
            nn.Dropout(self.drop_prob),
            nn.Linear(self.B1_dim, self.B1_dim),
        )

        self.criterion = nn.MSELoss()

        # ç”¨äºå­˜å‚¨æ³¨æ„åŠ›æƒé‡(ä¾¿äºå¯è§†åŒ–)
        self.attention_weights = {}

    def reparameterise(self, mu, logvar):
        if self.training:
            std = logvar.mul(0.5).exp_()
            eps = std.data.new(std.size()).normal_()
            return eps.mul(std).add_(mu)
        else:
            return mu

    def kl_loss(self, mu, logvar):
        KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)
        KLD = torch.sum(KLD_element, dim=-1).mul_(-0.5)
        KLD = torch.mean(KLD, dim=-1)
        return torch.mean(KLD, dim=0)

    def adaptive_weight_decay(self, epoch, max_epochs):
        """è‡ªé€‚åº”æƒé‡è¡°å‡"""
        decay = 1.0 - (epoch / max_epochs) * 0.3
        return max(decay, 0.7)

    def forward(self, x, acoustic, visual, epoch=0, max_epochs=40):
        # è·å–å½“å‰å¯å­¦ä¹ æƒé‡
        current_weights = self.learnable_weights.get_weights()
        beta = self.learnable_weights.beta
        gamma = self.learnable_weights.gamma
        lambda_weight = self.learnable_weights.lambda_weight

        # è‡ªé€‚åº”æƒé‡è¡°å‡
        decay_factor = self.adaptive_weight_decay(epoch, max_epochs)

        # ================== ç¬¬ä¸€å±‚å¤„ç† ==================
        # é—¨æ§ç“¶é¢ˆç¼–ç 
        mu1, logvar1, gate1_values, importance1_weights = self.gated_encoder1(x)
        kl_loss_0 = self.kl_loss(mu1, logvar1)

        # é‡å‚æ•°åŒ–
        b0 = self.reparameterise(mu1, logvar1)

        # è·¨æ¨¡æ€æ³¨æ„åŠ›(B0ç‰¹å¾å…³æ³¨å£°å­¦ç‰¹å¾)
        attended_b0, attention_weights_1 = self.text_acoustic_attention(
            query=b0, key=acoustic, value=acoustic
        )
        self.attention_weights['text_acoustic'] = attention_weights_1

        # ç»“åˆåŸå§‹å’Œæ³¨æ„åŠ›å¢å¼ºçš„ç‰¹å¾
        enhanced_b0 = b0 + 0.3 * attended_b0  # æ®‹å·®è¿æ¥

        # é‡æ„å£°å­¦ç‰¹å¾
        output1 = self.MLP1(enhanced_b0)
        mse_0 = self.criterion(output1, acoustic)

        # ç¬¬ä¸€å±‚ä¿¡æ¯ç“¶é¢ˆæŸå¤±
        IB0 = kl_loss_0 + beta * mse_0 * decay_factor

        # ================== ç¬¬äºŒå±‚å¤„ç† ==================
        # ä½¿ç”¨å¢å¼ºçš„b0ç‰¹å¾è¿›è¡Œç¬¬äºŒå±‚ç¼–ç 
        mu2, logvar2, gate2_values, importance2_weights = self.gated_encoder2(enhanced_b0)
        kl_loss_1 = self.kl_loss(mu2, logvar2)

        # é‡å‚æ•°åŒ–
        b1 = self.reparameterise(mu2, logvar2)

        # è·¨æ¨¡æ€æ³¨æ„åŠ›(B1ç‰¹å¾å…³æ³¨è§†è§‰ç‰¹å¾)
        attended_b1, attention_weights_2 = self.b0_visual_attention(
            query=b1, key=visual, value=visual
        )
        self.attention_weights['b0_visual'] = attention_weights_2

        # ç»“åˆåŸå§‹å’Œæ³¨æ„åŠ›å¢å¼ºçš„ç‰¹å¾
        enhanced_b1 = b1 + 0.3 * attended_b1  # æ®‹å·®è¿æ¥

        # é‡æ„è§†è§‰ç‰¹å¾
        output2 = self.MLP2(enhanced_b1)
        mse_1 = self.criterion(output2, visual)

        # ç¬¬äºŒå±‚ä¿¡æ¯ç“¶é¢ˆæŸå¤±
        IB1 = kl_loss_1 + gamma * mse_1 * decay_factor

        # ================== å¤šæ¨¡æ€èåˆ ==================
        # å°†ä¸åŒå±‚çš„ç‰¹å¾è¿›è¡Œèåˆ
        fusion_input = torch.cat([enhanced_b1, output1, output2], dim=-1)
        final_b1 = self.multimodal_fusion(fusion_input)

        # æ€»çš„ä¿¡æ¯ç“¶é¢ˆæŸå¤±
        IB_total = IB0 + lambda_weight * IB1

        # ğŸ”¥ è¿”å›é‡æ„ç»“æœ(ç”¨äºæ¶ˆèå®éªŒ)
        reconstructions = {
            'b0': enhanced_b0,  # ç¬¬ä¸€å±‚ç“¶é¢ˆç‰¹å¾
            'b1': enhanced_b1,  # ç¬¬äºŒå±‚ç“¶é¢ˆç‰¹å¾(çº¯B1)
            'acoustic_recon': output1,  # å£°å­¦é‡æ„
            'visual_recon': output2,  # è§†è§‰é‡æ„
            'final_b1': final_b1  # èåˆåçš„B1
        }

        # è¿”å›ç»“æœå’Œä¸­é—´å˜é‡(ç”¨äºåˆ†æ)
        intermediate_results = {
            'gate1_values': gate1_values,
            'gate2_values': gate2_values,
            'importance1_weights': importance1_weights,
            'importance2_weights': importance2_weights,
            'attention_weights': self.attention_weights.copy(),
            'current_weights': current_weights,
            'reconstructions': reconstructions,
            'gating_mode': self.gating_mode  # ğŸ”¥ æ·»åŠ é—¨æ§æ¨¡å¼ä¿¡æ¯
        }

        return final_b1, IB_total, kl_loss_0, mse_0, kl_loss_1, mse_1, intermediate_results


# ================== ä½¿ç”¨ç¤ºä¾‹å’Œè®­ç»ƒç›¸å…³ä»£ç  ==================

class ImprovedTrainingLoop:
    """æ”¹è¿›çš„è®­ç»ƒå¾ªç¯,åŒ…å«ç›‘æ§å’Œå¯è§†åŒ–åŠŸèƒ½"""

    def __init__(self, model, optimizer, scheduler, device):
        self.model = model
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device

        # ç›‘æ§æŒ‡æ ‡
        self.training_stats = {
            'weights_history': [],
            'attention_stats': [],
            'gate_stats': []
        }

    def train_epoch_improved(self, train_dataloader, epoch, max_epochs):
        """æ”¹è¿›çš„è®­ç»ƒepoch"""
        self.model.train()
        epoch_stats = {
            'total_loss': 0.0,
            'ib_loss': 0.0,
            'kl_losses': [],
            'mse_losses': [],
            'weight_changes': {},
            'attention_entropy': []
        }

        for step, batch in enumerate(train_dataloader):
            batch = tuple(t.to(self.device) for t in batch)
            input_ids, visual, acoustic, label_ids = batch

            # æ•°æ®é¢„å¤„ç†
            visual = torch.squeeze(visual, 1)
            acoustic = torch.squeeze(acoustic, 1)
            visual_norm = (visual - visual.min()) / (visual.max() - visual.min() + 1e-8)
            acoustic_norm = (acoustic - acoustic.min()) / (acoustic.max() - acoustic.min() + 1e-8)

            # å‰å‘ä¼ æ’­
            logits, IB_loss, kl_loss_0, mse_0, kl_loss_1, mse_1, intermediate = self.model(
                input_ids, visual_norm, acoustic_norm, epoch, max_epochs
            )

            # ä¸»ä»»åŠ¡æŸå¤±
            loss_fct = nn.MSELoss()
            main_loss = loss_fct(logits.view(-1), label_ids.view(-1))

            # æ€»æŸå¤±
            total_loss = main_loss + 0.1 * IB_loss  # å¯è°ƒæ•´IBæŸå¤±æƒé‡

            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            total_loss.backward()

            # æ¢¯åº¦è£å‰ª(é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸)
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

            self.optimizer.step()
            if self.scheduler:
                self.scheduler.step()

            # ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
            epoch_stats['total_loss'] += total_loss.item()
            epoch_stats['ib_loss'] += IB_loss.item()
            epoch_stats['kl_losses'].append([kl_loss_0.item(), kl_loss_1.item()])
            epoch_stats['mse_losses'].append([mse_0.item(), mse_1.item()])

            # æ”¶é›†æƒé‡å˜åŒ–ä¿¡æ¯
            current_weights = intermediate['current_weights']
            epoch_stats['weight_changes'] = current_weights

            # è®¡ç®—æ³¨æ„åŠ›ç†µ(è¡¡é‡æ³¨æ„åŠ›åˆ†å¸ƒé›†ä¸­ç¨‹åº¦)
            for key, attention_weights in intermediate['attention_weights'].items():
                entropy = self.calculate_attention_entropy(attention_weights)
                epoch_stats['attention_entropy'].append(entropy.item())

        # è®¡ç®—å¹³å‡ç»Ÿè®¡
        num_batches = len(train_dataloader)
        epoch_stats['total_loss'] /= num_batches
        epoch_stats['ib_loss'] /= num_batches
        epoch_stats['avg_attention_entropy'] = sum(epoch_stats['attention_entropy']) / len(
            epoch_stats['attention_entropy'])

        # ä¿å­˜è®­ç»ƒç»Ÿè®¡
        self.training_stats['weights_history'].append(epoch_stats['weight_changes'])
        self.training_stats['attention_stats'].append(epoch_stats['avg_attention_entropy'])

        return epoch_stats

    def calculate_attention_entropy(self, attention_weights):
        """è®¡ç®—æ³¨æ„åŠ›æƒé‡çš„ç†µ"""
        # attention_weights: [batch_size, seq_len, seq_len]
        # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„å¹³å‡æ³¨æ„åŠ›ç†µ
        batch_size = attention_weights.shape[0]
        entropies = []

        for i in range(batch_size):
            attn = attention_weights[i].mean(dim=0)  # å¹³å‡æ‰€æœ‰head
            attn = attn / (attn.sum(dim=-1, keepdim=True) + 1e-8)  # å½’ä¸€åŒ–
            entropy = -torch.sum(attn * torch.log(attn + 1e-8), dim=-1).mean()
            entropies.append(entropy)

        return torch.stack(entropies).mean()

    def print_training_stats(self, epoch, epoch_stats):
        """æ‰“å°è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n=== Epoch {epoch + 1} Stats ===")
        print(f"Total Loss: {epoch_stats['total_loss']:.4f}")
        print(f"IB Loss: {epoch_stats['ib_loss']:.4f}")
        print(f"Current Weights - Beta: {epoch_stats['weight_changes']['beta']:.2f}, "
              f"Gamma: {epoch_stats['weight_changes']['gamma']:.2f}, "
              f"Lambda: {epoch_stats['weight_changes']['lambda']:.2f}")
        print(f"Average Attention Entropy: {epoch_stats['avg_attention_entropy']:.4f}")
        print(f"KL Losses: Layer1={epoch_stats['kl_losses'][-1][0]:.4f}, "
              f"Layer2={epoch_stats['kl_losses'][-1][1]:.4f}")
        print(f"MSE Losses: Acoustic={epoch_stats['mse_losses'][-1][0]:.4f}, "
              f"Visual={epoch_stats['mse_losses'][-1][1]:.4f}")


# ================== é…ç½®å’Œä½¿ç”¨ç¤ºä¾‹ ==================

def create_improved_model(original_args):
    """åˆ›å»ºæ”¹è¿›çš„ITHPæ¨¡å‹"""

    # æ‰©å±•åŸå§‹å‚æ•°
    improved_args = original_args.copy()

    # æ·»åŠ æ–°çš„è¶…å‚æ•°
    improved_args.update({
        'use_attention': True,
        'use_gating': True,
        'use_learnable_weights': True,
        'attention_heads': 8,
        'gate_activation': 'sigmoid',
        'fusion_dropout': 0.1,
        'weight_decay_schedule': True
    })

    return ITHP(improved_args)


if __name__ == "__main__":
    # å‡è®¾ä½ åœ¨ global_configs é‡Œæœ‰å¯¹åº”çš„ç»´åº¦å®šä¹‰
    ITHP_args = {
        'X0_dim': global_configs.TEXT_DIM,
        'X1_dim': global_configs.ACOUSTIC_DIM,
        'X2_dim': global_configs.VISUAL_DIM,
        'inter_dim': 128,
        'drop_prob': 0.1,
        'max_sen_len': 50,
        'B0_dim': 64,
        'B1_dim': 64,
        'p_beta': 1.0,
        'p_gamma': 1.0,
        'p_lambda': 1.0,
    }

    model = ITHP(ITHP_args)
    print(model)   # æ‰“å°ç½‘ç»œç»“æ„
